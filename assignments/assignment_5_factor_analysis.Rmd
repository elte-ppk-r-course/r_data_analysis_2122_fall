---
title: "Assignment 6: Factor Analysis"
author: "Marton Kovacs / Zoltan Kekecs"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction

In this lab assignment you will need to explore the factor structure of the Animal Rights Scale, a scale containing 28 items to measure attitudes towards animal experimentation and animal rights. Imagine that you are a researcher who is interested in the underlying factors that govern attitudes towards animal rights and the use of animals for different purposes. You have gathered data using the Animal Rights Scale (ARS) from 154 individuals in an online survey. Your goal is to explore the underlying factors.

# Dataset

You can load the dataset from the 'data/' folder.

The dataset includes the responses of 154 individuals on the following variables:

__ar1-ar28__ contain the data from the 28 items of the ARS. Participants had to rate their agreement with each statement separately on a 1-5 Likert scale with the following anchors: 1 - strongly disagree, 2 – disagree, 3 - no opinion, 4 – agree, 5 - strongly agree.

The questions in the ARS were the following:

  * __ar 1.__ Humans have no right to displace wild animals by converting wilderness areas into farmlands, cities, and other things designed for people.
  * __ar 2.__ Animal research cannot be justified and should be stopped.
  * __ar 3.__ It is morally wrong to drink milk and eat eggs.
  * __ar 4.__ A human has no right to use a horse as a means of transportation (riding) or entertainment (racing).
  * __ar 5.__ It is wrong to wear leather jackets and pants.
  * __ar 6.__ Most medical research done on animals is unnecessary and invalid.
  * __ar 7.__ I have seriously considered becoming a vegetarian in an effort to save animal lives.
  * __ar 8.__ Pet owners are responsible for preventing their pets from killing other animals, such as cats killing mice or snakes eating live mice.
  * __ar 9.__ We need more regulations governing the use of animals in research.
  * __ar 10.__ It is morally wrong to eat beef and other "red" meat.
  * __ar 11.__ Insect pests (mosquitoes, cockroaches, flies, etc.) should be safely removed from the house rather than killed.
  * __ar 12.__ Animals should be granted the same rights as humans.
  * __ar 13.__ It is wrong to wear leather belts and shoes.
  * __ar 14.__ I would rather see humans die or suffer from disease than to see animals used in research.
  * __ar 15.__ Having extended basic rights to minorities and women, it is now time to extend them also to animals.
  * __ar 16.__ God put animals on Earth for man to use.
  * __ar 17.__ There are plenty of viable alternatives to the use of animals in biomedical and behavioral research.
  * __ar 18.__ Research on animals has little or no bearing on problems confronting people.
  * __ar 19.__ New surgical procedures and experimental drugs should be tested on animals before they are used on people.
  * __ar 20.__ I am very concerned about pain and suffering in animals.
  * __ar 21.__ Since many important questions cannot be answered by doing experiments on people, we are left with no alternatives but to do animal research.
  * __ar 22.__ It is a violation of an animal's rights to be held captive as a pet by a human.
  * __ar 23.__ It is wrong to wear animal fur (such as mink coats).
  * __ar 24.__ It is appropriate for humans to kill animals that destroy human property, for example, rats, mice, and pigeons.
  * __ar 25.__ Most cosmetics research done on animals is unnecessary and invalid.
  * __ar 26.__ It is morally wrong to eat chicken and fish.
  * __ar 27.__ Most psychological research done on animals is unnecessary and invalid.
  * __ar 28.__ Hunters play an important role in regulating the size of deer populations.

You can get more information about the ARS here: http://core.ecu.edu/psyc/wuenschk/Animals/Anim-Rights-Q.htm

And also here: 

Wuensch, K. L., Jenkins, K. W., & Poteat, G. M. (2002). Misanthropy, idealism, and attitudes towards animals. _Anthrozoös, 15_, 139-149

Sharp, H. W., Wuensch, K. L., Eppler, M. A., & Harju, B. L. (2006, April). Narcissism, empathy, and attitudes towards animals. In _Spring Conference of the North Carolina Psychological Association and North Carolina Psychological Foundation, Charlotte, NC._

A few other questions were also included in the questionnaire:

__sex:__ The self reported sex of the participant. This is a categorical variable coded as 1 – female, 2 – male.

__party:__ Self reported party affiliation of the person (in the USA). This is a categorical variable coded as 1 - democrat, 2 - republican, 3 - other, 4 – none.

__liberal:__ This variable contains data from a question: please rate how conservative or liberal are you. On a scale of 1-5 where 1 means very conservative and 5 means very liberal. 

# Task

Your task is to do an exploratory factor analysis using the items in the ARS to identify the latent factors underlying the responses. First of all, start by exploring the descriptive statistics and correlations in the dataset to get more familiar with it and to identify any unusual cases or coding errors. Make sure to check the assumptions of factorability and multivariate normality and address them as necessary. You have a free hand in choosing the extraction and rotation methods. You can also exclude items if you see this necessary, but __do not exclude more than 8 items__ in this assignment. (If you still find the average communality below expectations, just report this as a limitation in your report, but continue the task). Keep notes of the steps and different setting/methods you tried during the exploratory factor analysis. 

_(The factor structure of this scale has been previously analyzed by others. If you want, you can use these previous research reports to guide your exploration, or you can ignore them. In any case, do not base your decisions solely on these research reports. Do your own work and base your decisions on your own findings on this dataset.)_

When you have arrived at the factor structure you consider final, give names to the factors you derived from the data. Save the factor scores and build a linear regression model to predict how conservative or liberal participants are (using the “liberal” variable as a dependent variable) with the factors you identified as the predictors.

__To simplify the task you can regard all likert scale variables (ar1-28 and liberal) as if they were continuous variables!__ So you do not have to use polychoric correlation for factor analysis and you do not have to perform ordinal regression.

# What to report

Report if you have found any unusual things (outliers or coding errors) in the dataset and how you dealt with them. Report the results of the assumption checks for factorability and multivariate normality. If any of the assumptions were found to be violated, report what was done to handle that. 

Report the number of factors you chose to keep in your final factor structure and give a rationale why. Include the parallel analysis scree plot in your report. Report the post-extraction eignevalues, variance explained, and cumulative variance explained by the final factors in a table format. Report the average post-extraction communality of the items. 

Report which rotation you chose to use (if any) and why. Report the final factor structure including the factor names. Also, report the post-extraction commonalities of each item and the loadings of the items on the final factors in a table format. (These can be reported in the same table). This table should contain the loadings that you used to interpret the factors in your analysis (e.g. the loadings listed in the rotated factor matrix or the pattern matrix). The table should be structured in a way to help the reader easily see which items load high on which factors.

Report if you have excluded any items, and give a rationale for each. 

Report which factor (if any) was the most influential predictor of how liberal a person is in the linear regression model and explain what do you base this assessment on.

# What to discuss

Talk about the limitations of your study and findings. 

# Solution

## Read the data

Read the Animal Rights Scale (ARQ) dataset from the 'data/' folder. Pay attention to the extension.

```{r}
asr_raw <- readr::read_csv('https://raw.githubusercontent.com/andr3ahor/r_data_analysis_2122_fall/master/data/assignment_5_dataset.csv')
library(psych)
library(Hmisc)
```

## EDA

```{r}
str(asr_raw)
summary(asr_raw)

#NA detection
library(dplyr)
library(visdat)
which(is.na(data_frame), arr.ind=TRUE)
sum(is.na(asr_raw)) #11 hiányzó adat
colSums(is.na(asr_raw)) #oszlponokénti hiányzók

#Let's see the NA  --> there is only 0.2% missing, they are probly random NA's. 
visdat::vis_miss(asr_raw)

#I choose to replace NAs with the median. i didn't want to loose any data, and this seemed a good idea. I could have left out them during the calculations (na.rm = TRUE), but I wanted to use the factors with even data input. 
tidy_asr <- asr_raw %>% 
    mutate_if(is.numeric, function(x) ifelse(is.na(x), median(x, na.rm = T), x))



#I couldn't figure out wether the turned items has been turned already.

#Visuals
par(mar=c(1,1,1,1)) #i got this message: Error in plot.new() : figure margins too large
hist(tidy_asr[c(1:28)])

data <- tidy_asr[1:154, 1:28]
df <- data.frame(tidy_asr)

#Otlier data detection 
boxplot(tidy_asr[c(1:28)])
outliers <- psych::outlier(data)
#There are several outliers. I want to do EFA, therefore I left these data in my analysis. However I will measure my analysis based on this.

#The informations gathered on data
psych::describe(data)
```

## Data manipulation

Recode the sex and party variables as factor type variables with the following levels:
  * sex: 1 - male, 2 - female
  * party: 1 - democrat, 2 - republican, 3 - other, 4 - none

```{r}
recoded <- tidy_asr %>% mutate(sex = recode(sex, "1" = "male","2" = "female"))

recoded <- tidy_asr %>% mutate(party = recode(party, 
                                 "1" = "democrat",
                                 "2" = "republican",
                                 "3" = "other",
                                 "4" = "none"))

```

# Creating a correlation matrix

__Note:__ Remember to only include the variables of the questionnaire that will be part of the factor analysis.

```{r}
library(ggcorrplot)
library(ggplot2)

```

Create the correlation matrix.

```{r}
asr.cor <- cor(data) 
asr.cor <- round(asr.cor, 2)
asr.rcorr<-rcorr(as.matrix(data))
valtozo <- round(asr.rcorr$P, 2) #There are some insignificant correlations, but the most are significant. 
```

## Visualizing the correlation matrix

Create a visualization of the results of the correlation matrix.

```{r}
library(psycho)
library(tidyverse)
library(corrplot)

p1 <- ggcorrplot(asr.cor, 
           hc.order = FALSE, 
           type = "upper",
           lab = FALSE)

corrplot(asr.cor, method = "color",  
         type = "lower", order = "original", 
         addCoef.col = "black", 
         tl.col = "darkblue", tl.srt = 45,
         sig.level = 0.01,  
         diag = FALSE)
#Saved the plots into assignments/assignment_5 folder
```

## Test for factorability

Calculate the KMO score.

```{r}
# library(psych) must be used

asr_kmo <- KMO(data)
print(asr_kmo)
#overall MSA = 0.88, smallest: ar28= 0.77 --> All in all the KMO is quite good.

#I chekced, but removing item 28 would not change it.
asr_kmo2 <- KMO(data[c(1:27)])
print(asr_kmo)

#I choose to leave every item inside.
```

## Test for multivariate normality

```{r}
#install.packages("mvnormtest")
library(mvnormtest)
#install.packages("MVN")
library(MVN)

#Mardia’s MVN test
result <- mvn(data, mvnTest = "mardia")
result$multivariateNormality

# Henze-Zirkler’s MVN test
result.hz <- mvn(data, mvnTest = "hz")
result.hz$multivariateNormality

# Shapiro-Wilk
result.sh <- mshapiro.test(t(data))

#All tests show that there is no MVN, the normality is corrupted. Therefore I won't be able to do maximum likelyhood analysis.

#Bartlett, as my last chance
bartlett <- cortest.bartlett(data)
#p value is godd, the EFA can be done as there is some level of correlation. 
```

Test for skewness and kurtosis.

```{r}
#install.packages("QuantPsyc")
library(QuantPsyc)
normality <- mult.norm(data)$mult.test
print(normality) #Skewness and peaks are corrupted. But the KMO is quite godd, and the Bartlett's as well - therefore I proceed with the analysis.

```

## Create scree plot

Create a scree plot to help the decision on how many factors to include.

```{r}
scree(data)
#Plot saved to assingment_5 folder
#It shows that there could be 1, 2 or 6 cators based on where the line brakes. 

#I also made a paralell scree plot - saved to folder.
fa.parallel(data)

#It shows that 2 or 3 factors could be there. Based on this i choose 3 factor model. 
```

## Run the factor analysis

Run the factor analysis with the chosen number of factors.

```{r}
#install.packages("GPArotation")
library(GPArotation)

# 3 factors, oblimin rotation - because I expect correlation between factors.
efa3 <- fa(data,
          nfactors = 3,
          fm="pa",
          rotate = "oblimin")



fa.diagram(efa3) #The 2. factor is rather unstable, and has few items. Therefore I redo the model with 2 factors - according to scree plot simulation.

efa2 <- fa(data,
          nfactors = 2,
          fm="pa",
          rotate = "oblimin")

fa.diagram(efa2)

#This is much better, the factor loadings are good. Only the 8th item is left out from these two factors. I would eliminate it from the final questionnaire.  

#Visuals saved to assignment 5 folder.

```

Sort the communality scores in decreasing order.

```{r}

communa2 <- efa2$communality
commun2 <- sort(communa2, decreasing = TRUE)
commun2 <- round(commun2, 3)

#cumulative variance
round(efa2$Vaccounted,2)

#eigen values
eigen <- efa3$e.values
eigen <- round(eigen,3)

```

Calculate the mean communality scores.

```{r}
mean_c2 <- mean(commun2)

```

Show the factor loadings for the chosen factor structure.

```{r}
load <- efa2$loadings
fac1 = efa2$loadings[,1]
fac2 = efa2$loadings[,2]

#these are the factor loadings
factors <- data.frame(F1_rights = fac1 , 
           F2_research = fac2)
factors <- round(factors,3) 

#I checked which item, how big loading have in wich factor. 
factors[1,][which.min(factors[1,])] <- ""
factors[2,][which.min(factors[2,])] <- ""
factors[3,][which.min(factors[3,])] <- ""
factors[4,][which.min(factors[4,])] <- ""
factors[5,][which.min(factors[5,])] <- ""
factors[6,][which.min(factors[6,])] <- ""
factors[7,][which.min(factors[7,])] <- ""
factors[8,][which.min(factors[8,])] <- ""
factors[9,][which.min(factors[9,])] <- ""
factors[10,][which.min(factors[10,])] <- ""
factors[11,][which.min(factors[11,])] <- ""
factors[12,][which.min(factors[12,])] <- ""
factors[13,][which.min(factors[13,])] <- ""
factors[14,][which.min(factors[14,])] <- ""
factors[15,][which.min(factors[15,])] <- ""
factors[16,][which.max(factors[16,])] <- ""
factors[17,][which.min(factors[17,])] <- ""
factors[18,][which.min(factors[18,])] <- ""
factors[19,][which.max(factors[19,])] <- ""
factors[20,][which.min(factors[20,])] <- ""
factors[21,][which.max(factors[21,])] <- ""
factors[22,][which.min(factors[22,])] <- ""
factors[23,][which.min(factors[23,])] <- ""
factors[24,][which.max(factors[24,])] <- ""
factors[25,][which.min(factors[25,])] <- ""
factors[26,][which.min(factors[26,])] <- ""
factors[27,][which.max(factors[27,])] <- ""
factors[28,][which.max(factors[28,])] <- ""


```

Visualize the factor structure.

```{r}
#install.packages("kableExtra")
library(kableExtra)

fa.diagram(efa2) #final names?

#Here are them:
colnames(efa2$loadings) <- c("F1:Attitude to animal's rights", "F2:Attitude to animal research")
final <- fa.diagram(efa2) #saved as final_efa2 in folder

#Final table: Factor loadings és eigen_v, communality
table1 <- cbind(Communality = commun2, Eigen_v = eigen, factors)
table1 <- arrange(table1, desc(F1_rights),desc(F2_research))

table1 %>%
    kbl() %>%
    kable_styling()

#Also table2 with the facto lodaings
table2 <- table1[c("F1_rights","F2_research")]

table2 %>%
    kbl() %>%
    kable_styling()

#cumulative variance
Cum_var <- round(efa2$Vaccounted,2)



```

## Run linear regression

Calculate the factor scores.

```{r}
scores <- round(efa2$scores, 1)
```

Bind factor scores to the original dataset.

```{r}
regr_data <- cbind(scores, tidy_asr)
regr_data <- regr_data %>% 
       rename(
               F1_rights = PA1,
               F2_research = PA2)
```

Run the logistic regression.

```{r}
#Predict the liberality by F1 and F2
library(readxl)
lmliberal = lm(liberal~F1_rights+F2_research, data = regr_data)
summary(lmliberal)

#The F shows, that our analysis were significant in which the F1_rights predicts significantly, while the F2 doesn't predict significantly with  a 17% chance.
#The R2 is enough good, the predictions doesn't really fit.

plot(lmliberal, pch = 16, col = "blue") #saved 2 residual picture. There is a big difference between real and predicted.  
plot(lmliberal$residuals, pch = 16, col = "red") #It seems that the residuals are quite random, there is no hidden pattern. I saved this by the random_residual name in the folder.

#Discussion

#If I would approach again, I would remove or handle better the outlier data. I would compare that model with this one for the differences. I would probably remove the 5th or 13th items as they correalte heavily. They have very similar meaning. Also it would be great to repeat the analysis on a bigger sample. Then I would have a better chance to remove NAs without loosing too much information. 
```

